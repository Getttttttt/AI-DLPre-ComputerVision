## GANs

### 1. GAN的基本原理

![image-20240311022112882](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20240311022112882.png)

生成对抗网络（GAN）由两部分组成：生成器（Generator, G）和判别器（Discriminator, D）。生成器的目标是生成逼真的数据（如图像），而判别器的目标是区分真实数据和生成器生成的假数据。

- 生成器（G）：接收一个==随机噪声向量==作为输入，并通过这个噪声生成数据。生成器的目标是生成足够好的数据，以至于判别器**==无法区分==**它们和真实数据的差别。

- 判别器（D）：判断输入的数据是真实的还是由生成器生成的，即区分真实数据和假数据。

==注意==：两个网络在训练过程中相互竞争！生成器试图提高生成数据的质量，而判别器则试图更好地识别真假数据。这个过程如同一个博弈，最终目标是**达到一个平衡点**，即生成器生成的数据无法被判别器区分。

==原生的GAN生成图像清晰度不够，并且完全随机生成，所以有了GAN的变体==

### 2. DCGAN

引入原因：

- **图像质量提升**：原始GAN在生成高质量图像方面存在挑战，DCGAN通过使用深度卷积网络改善了图像的质量和细节。
- **训练稳定性**：GAN的训练过程可能非常不稳定。DCGAN通过引入批量归一化和去除全连接层等技术，提高了训练过程的稳定性。

效果对比：

![image-20240311024816733](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20240311024816733.png)

基本原理：

![image-20240311024937143](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20240311024937143.png)

![image-20240311024946427](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20240311024946427.png)

DCGAN的生成器通常从一个随机噪声向量开始，通过一系列反卷积层逐渐上采样，直到达到所需的图像尺寸。每一层的输出都通过批量归一化和ReLU激活函数（最后一层通常使用tanh激活函数）。判别器则采用相反的结构，从输入图像开始，通过一系列卷积层逐渐下采样，直到得到一个单一的预测输出。这个输出表示判别器对图像是真实还是生成的判断。在判别器的每一层中，批量归一化和Leaky ReLU激活函数被用来促进稳定的梯度流动。

**使用全卷积网络结构来提高图像质量**

> demo——利用微笑训练模型，可以生成微笑，见`demo_DCGAN`  模型已经训练好，训练结果见`out`文件夹（100张图片可以用那种快速点映进行展示，可以看到训练的过程）还可以加载模型看总的效果

### 3. cGAN

引入原因：

- **控制生成内容**：原始GAN生成的图像是随机的，而cGAN允许用户指定生成图像的条件，如类别或属性，从而控制生成内容。
- **多样化应用**：cGAN可以用于多种有条件约束的生成任务，如图像编辑、数据增强等。

基本原理：

![image-20240311030018393](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20240311030018393.png)

==**删除条件向量y就是GAN**==

cGAN是一种生成对抗网络，它在传统GAN的基础上引入了额外的条件信息，使得生成的数据可以根据这些条件进行定向生成。这些条件可以是类别标签、文本描述、图像等。

**生成器（G）**：在cGAN中，生成器接收两个输入：一个随机噪声向量和条件信息。这些输入通常在网络内部结合起来，例如通过连接（concatenation）或其他方式，以便生成器可以根据这些条件生成相应的数据。

**判别器（D）**：判别器同样接收两个输入：一个数据样本（可以是真实的或由生成器生成的）和相同的条件信息。判别器的任务是判断给定条件下，样本是否为真实数据。

在训练过程中，生成器和判别器都会考虑条件信息，生成器尝试生成符合条件的假数据，而判别器尝试区分真实数据和生成的假数据。通过这种方式，cGAN能够生成与给定条件相匹配的数据。

#### 3.1 有监督的cGAN

在有监督的cGAN中，训练数据包含了标签或其他形式的条件信息。例如，如果条件是图像的类别，那么每个训练图像都会有一个相应的类别标签。生成器和判别器在训练过程中使用这些标签来生成和评估数据。有监督的cGAN通常用于那些有大量标记数据的任务，如条件图像合成、数据增强等。

> 应用demo：有条件的生成动漫头像，比如指定头发啥颜色等（代码已下载，未运行）

#### 3.2 无监督的cGAN

无监督cGAN不依赖于标记的训练数据。相反，它可能依赖于模型自身来发现数据中的条件信息，或者使用未标记数据中的隐含结构。无监督cGAN可以用于聚类、特征学习等任务，其中条件信息不是显式提供的，而是需要模型自己学习和发现。（这个其实通常可以用cycleGAN实现）

> 应用Demo：为人脸图片换表情，注意不换脸，就是表情（换啥表情是自己学的，控制不了）（代码已下载，未运行），这个地方可以用我们自己的脸！

### 4. 风格化生成StyleGAN

引入原因：

- **高分辨率图像生成**：随着对高质量图像需求的增加，StyleGAN被设计来生成**高分辨率**（==极高==）且细节丰富的图像。
- **风格控制**：StyleGAN通过映射和合成网络分离了内容和风格，允许用户更精细地控制生成图像的==风格特征==。

原论文内容：（原理看不懂。。。）

StyleGAN 的网络结构包含两个部分，第一个是**Mapping network**，即下图 (b)中的左部分，由隐藏变量 z 生成 中间隐藏变量 w的过程，这个 w 就是用来控制生成图像的style，即风格。第二个是**Synthesis network**，它的作用是生成图像，创新之处在于给每一层子网络都喂了 A 和 B，A 是由 w 转换得到的仿射变换，用于控制生成图像的风格，B 是转换后的随机噪声，用于丰富生成图像的细节，即每个卷积层都能根据输入的A来调整**"style"**。整个网络结构还是保持了 **PG-GAN （progressive growing GAN）** 的结构。

![image-20240311031108513](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20240311031108513.png)

论文效果（AI换脸）：

![img](https://pic2.zhimg.com/80/v2-1cd2e45a25531cedcb10e21714ff5a31_1440w.webp)

> 源代码已下载，但是还没有运行，但是这个就算运行了效果也是如上的

### 5. 风格迁移CycleGAN

这个最有意思

需求：

- **无成对训练数据**：在许多实际应用中，成对的训练数据（如在不同风格之间转换的图像对）很少。CycleGAN通过循环一致性损失解决了这个问题，允许在没有成对数据的情况下进行风格迁移。
- **域转换**：CycleGAN可以在不同的图像域之间进行转换，这对于艺术风格迁移、季节变化模拟等任务非常有用。

这个原理更抽象

我自己理解的人话版：

假如两个域X（图片）和Y（另外一个风格的图片），针对X有一个生成器GX和一个判别器DX，针对Y有一个生成器GY和一个判别器DY，GX把X中的一个图片生成假图片，但是生成的假图片在Y域风格中，DY会进行判断这里是哪里的假图片，GY把假图片又转换回去，注意新的假图片落到X中，DX也是会判断，但是新的假图片肯定与原图不一样，现在计算这两种图片的“损失”（循环一致性损失），于是就开始慢慢训练。。。
![image-20240311040835967](C:\Users\dell\AppData\Roaming\Typora\typora-user-images\image-20240311040835967.png)

> 这个代码我都不知道能不能实现，找了好几个，反正都失败了。。。。